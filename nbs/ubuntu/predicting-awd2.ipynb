{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hendrix/projects/LanguageModel'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = Path('/home/hendrix/data/jhlm/')\n",
    "df = pd.read_csv(path/'alllessons3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/hendrix/data/jhlm/alllessons.csv'),\n",
       " PosixPath('/home/hendrix/data/jhlm/data_save.pkl'),\n",
       " PosixPath('/home/hendrix/data/jhlm/jhlm3_lm.pkl'),\n",
       " PosixPath('/home/hendrix/data/jhlm/jhlm.pkl'),\n",
       " PosixPath('/home/hendrix/data/jhlm/tmp_lm'),\n",
       " PosixPath('/home/hendrix/data/jhlm/alllessons2.csv'),\n",
       " PosixPath('/home/hendrix/data/jhlm/alllessons3.csv'),\n",
       " PosixPath('/home/hendrix/data/jhlm/split'),\n",
       " PosixPath('/home/hendrix/data/jhlm/tmp_lm_small'),\n",
       " PosixPath('/home/hendrix/data/jhlm/excel'),\n",
       " PosixPath('/home/hendrix/data/jhlm/models'),\n",
       " PosixPath('/home/hendrix/data/jhlm/original'),\n",
       " PosixPath('/home/hendrix/data/jhlm/alllessons.xlsx'),\n",
       " PosixPath('/home/hendrix/data/jhlm/alllessons3.xlsx')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = (language_model_learner(data_lm,AWD_LSTM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname='jhlm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(path,'jhlm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is really cool , as the United States Department of Agriculture ( WHO ) has been working with the United States Department of Agriculture ( WHO ) to create a \" Special Mission \" to help the American people .\n"
     ]
    }
   ],
   "source": [
    "print(learn.predict('this is really cool',50,temperature=.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my best tips are i think like oh yeah i 've got something that cleans up my whatsapp it 's a deep learning application i wrote last week why not like it 's so\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('my best tips are', 30, beam_sz=200,temperature=.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my best tips are i think like oh yeah i 've got something that cleans up my whatsapp it 's a deep learning application i wrote last week why not like it 's so\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('my best tips are', 30, beam_sz=200,temperature=.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i think its really cool work pretty well this is an example of a computer vision based approach on something which originally was n't actually images so that was yeah that 's a really cool\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('i think its really cool', 30, beam_sz=200,temperature=.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i think its really cool that you can do this with what i 've learned it can also be intimidating to think like wow these people are doing amazing things but it 's important to realize\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('i think its really cool that', 30, beam_sz=200,temperature=.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its a really good idea to not just look at the pictures but also look at the labels and so all of the possible label names accord your classes that 's where the data bunch you\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('its a really good idea to', 30, beam_sz=200,temperature=.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camvid and things looking good i always like to save where i 'm up to to save me the 54 seconds of going back and doing it again and as very usual we unfreeze the rest of our model we 're going to be learning more about what that means during the course and then we run the learning rate finder and plot it tells you exactly what to type and we take a look now we 're going to be learning about learning rates today actually but for now here 's what you need to know on the learning rate finder what you 're xxbos the start of the tree . So that works out really well and that 's u - Net . This is the unit code from fast.ai , and the key thing that comes in is the encoder . The encoder refers\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('camvid', 150, beam_sz=200,temperature=.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate finder graph yeah i mean it 's a great question yeah i mean the short answer is no and the reason the answer is no is because this is still a bit more artisinal than i would like you know as you can kind of see i 've been kind of saying how i read this learning rate graph depends a bit on what stage i 'm at and kind of what the shape of it is i guess like the when you 're just training the head so before you unfreeze it pretty much always looks like this and you \" xxbos \" this set of transforms and we 're going to transform into something of this size and then we 're going to convert them into a data bunch so each of those stages inside these parentheses of various parameters you can pass to customize how that all works\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('learning rate finder', 150, beam_sz=200,temperature=.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gan . So first you create the item list , then you split it , then you label it . Next thing we can do is to add transforms . In this case , we 're not going to use the normal get_transforms function because we 're doing digit recognition and digit recognition , you would n't want to flip it left right . That would change the meaning of it . You would n't want to rotate it too much , that would change the meaning of it . Also because these images are\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('gan', 100, temperature=.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to use a gan and basically the same thing as plot top losses so in other words these are the ones which is either wrong about or at least confident about and so not surprisingly this one here does not appear to be a teddy bear or a black bear or a brown bear right so this should n't be in our data set so what i do is i work on the delete button okay and all the rest do look indeed like bears and then so i can click confirm and it 'll bring up another five what 's that is that\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('to use a gan', 100, temperature=.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should n't be there and we 're going to remove them from a validation set so that our metrics will be more correct you then need to rerun these two steps replacing valid des with trained yes to clean up your training set to get the noise out of that as well so it 's a good practice to do both we 'll talk about test sets later as well if you also have a test set you would then repeat the same thing so we run failed a leader passing in that sort of list of paths and so what\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('You should', 100, temperature=.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its a good idea to it turns out that the missingness is important it can use the interaction of competition distance na and competition distance to make predictions so that 's what fixed missing does you do n't have to manually call pre processes yourself when you call any kind of item list creating creator you can pass in a list of pre processes which you can create like this ok so if this is saying ok i want to feel missing i want to category Phi i want to normalize so for continuous variables it 'll subtract the mean and divide by the\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('Its a good idea to', 100, temperature=.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in training a language model on all of Wikipedia , and then we can make that available to all of you . Just like a pre - trained imagenet model for vision , we 've now made available a pre - trained Wikitext model for NLP not because it 's particularly useful of itself ( predicting the next word of sentences is somewhat useful , but not normally what we want to do ) , but it 's a model that understands a lot about language and a lot about what language describes . So then ,\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('in training', 100, temperature=.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in training on your particular phone lot of people think like oh if i want something on my phone i have to create some kind of mobile tensorflow onn x whatever tricky mobile app you really do n't you can run it all in the cloud and make it just a web app or use some kind of simple little GUI front - end that talks to a back end it 's not that often that you 'll need to actually run stuff on the phone so this is a good example of that see Werner has created a guitar\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('in training', 100, temperature=.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in training set as well and retrain your model so i 'll just note here that what our San Francisco study group did here was that they actually built a little app inside Jupiter notebook which you might not have realized as possible but not only is it possible it 's actually surprisingly straightforward and just like everything else you can hit double question mark to find out their secrets so here is the source code okay and really if you 've done any GUI programming before it 'll look incredibly normal you know there 's there 's\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('in training', 100, temperature=.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in training set so at this point i now have a bears folder containing a grizzly folder and a Teddy 's folder and the black folder in other words i have the basic structure we need to create an image data bunch to start doing some deep learning so let 's go ahead and do that now very often when you get when you download a data set from like Kaggle or from some academic data set there will often be a folder called train and a folder called valid and a folder called test right containing the different data\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('in training', 100, temperature=.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u net . So first you create the item list , then you split it , then you label it . Next thing we can do is to add transforms . In this case , we 're not going to use the normal get_transforms function because we 're doing digit recognition and digit recognition , you would n't want to flip it left right . That would change the meaning of it . You would n't want to rotate it too much , that would change the meaning of it . Also because these images are\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('u net', 100, temperature=.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network okay so we can then have a look at head which remembers the first few rows and there is our user ratings user movie rating and let 's make it more fun let 's see what the movies actually are i 'll just point something out here which is there 's this thing called encoding equals i 'm going to get rid of it and i get this error Unicode i just want to point this out because you 'll all see this at some point in your lives codec ca n't decode blah blah blah what this means is that this is not a Unicode xxbos that means that we can compare two baselines because everybody basically they say hey if you 're going to compare the baselines make sure you all use the same data set here 's the one you should use unfortunately it means\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('network', 150, temperature=.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network okay so we can then have a look at head which remembers the first few rows and there is our user ratings user movie rating and let 's make it more fun let 's see what the movies actually are i 'll just point something out here which is there 's this thing called encoding equals i 'm going to get rid of it and i get this error Unicode i just want to point this out because you 'll all see this at some point in your lives codec ca n't decode blah blah blah what this means is that this is not a Unicode xxbos and create labels using the kind of thing that actually image net specifically learn to ignore so the projection that you see we can click these layer buttons at the top to switch to user projection using a different layer of the neural net right and so here 's the last layer which is going to be a total waste of time for us because it 's really going to be projecting things based on what kind of thing it thinks it is and the first layer is probably going to\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('network', 200, temperature=.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for this architecture is from academic datasets academic datasets are really important they 're really interesting they 're things where academics spend a lot of time curating and gathering a data set so that they can show how well different kinds of approaches work with that data though the end here is they try to design data sets that are challenging in some way and require some kind of breakthrough to do them well so we 're going to be starting with an academic data set called the pet data set the other kind of data set we 'll be using during the\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('for this architecture', 100, temperature=.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for this architecture is a pre - trained model that 's been trained to do something different to what we 're doing with it . For imagenet , that was originally built as a model to predict which of a thousand categories each photo falls into . And people then fine - tune that for all kinds of different things as you 've seen . So we 're going to start with a pre - trained model that 's going to do something else . Not movie review classification . We 're going to start with a pre\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('for this architecture', 100, temperature=.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this architecture AI with no dot is the name of our software and then first dot AI with the dot is the name of our organization so if you go to dark start fast AI this is the fast a i might be okay well learn more about it in a moment but for now just realize everything we are going to do is going to be using basically either first AI or the thing that fast AI sits on top of which is platform height watch is one of the most popular libraries for deep learning\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('this architecture', 100, temperature=.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this architecture i 've done here is we 've actually got a matrix multiply that is creating this these output activations right but it 's doing it in a very interesting way which is it 's effectively finding a particular row when the input matrix so having done that we can then multiply those two sets together just a dot product and we can then find the loss squared and then we can find the average loss and lo and behold that number 0.39 is the same as this number because they 're doing the same thing so this one was kind\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('this architecture', 100, temperature=.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
